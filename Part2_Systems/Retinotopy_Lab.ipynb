{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retinotopy Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Author:  Dan Mossing, Biophysics PhD student in the Adesnik Lab at UC Berkeley`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topographic maps seem to be a fundamental organizing principle of primary sensory cortex. In this lab, we will examine the retinotopic organization of neurons in primary visual cortex based on calcium imaging data.\n",
    "\n",
    "Here, we have transgenically labeled somatostatin-expressing interneurons with the fluorescent calcium reporter GCaMP6s, and used two photon imaging to record several planes at varying depths in layer 2/3 through a cranial window. Meanwhile, a monitor shows small, isolated patches of drifting black and white gratings in various locations, against a gray screen.\n",
    "\n",
    "As in many sensory neuroscience experiments, the stimulation computer here delivers known stimuli, precisely timed and randomly interleaved. A TTL pulse from the stimulation computer to the acquisition computer allows us to record the precise timing of the stimuli relative to the recorded neural activity. We start by using an array of inferred \"event rates\" computed from the raw fluorescence data, an array of stimulus parameters, and a vector of stimulus times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('nbAgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage.measurements as snm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, fixed, HTML\n",
    "import ipywidgets as widgets\n",
    "import sklearn.linear_model\n",
    "import sklearn.cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data necessary for this lab\n",
    "np_file = np.load(\"data/retinotopy_files.npz\")\n",
    "\n",
    "event_rate = np_file['event_rate'] # the (N,T) event rate data, where N is the number of cells, and T is the number of frames in the experiment\n",
    "\n",
    "max_projection = np_file['max_projection'] # a max intensity projection of the data, in z and in time\n",
    "# anterior is left-to-right, medial is bottom-to-top\n",
    "\n",
    "pix_um = np_file['pix_um'] # width of an imaging pixel, in microns (um)\n",
    "\n",
    "stim_frame = np_file['stim_frame'] # a (K,2) vector indicating onset and offset of each stimulus\n",
    "\n",
    "stim_location = np_file['stim_location'] # a (K,2) vector indicating (elevation,azimuth) of each stimulus\n",
    "\n",
    "depth = np_file['depth'] # a (N,) vector indicating the plane of each ROI. Lower numbers are deeper planes, and the planes are separated by 50 um\n",
    "\n",
    "sq_deg = np_file['sq_deg'] # the interval at which visual stimuli tile the monitor, in visual degrees\n",
    "\n",
    "imaging_Hz = np_file['imaging_Hz'] # rate at which a given plane is sampled, in Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This data is large, had to be saved into two files to avoid github errors\n",
    "roi_mask = np.vstack((np.load(\"data/roi_mask_pt1.npy\"), np.load(\"data/roi_mask_pt2.npy\")))\n",
    "# This holds binary masks of the N segmented ROIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's look at the picture of all of our cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(max_projection)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, overlaying the segmented ROIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "overlay = np.zeros(max_projection.shape+(3,))\n",
    "overlay[:,:,0] = roi_mask.max(0)\n",
    "overlay[:,:,1] = max_projection/max_projection.max()\n",
    "plt.imshow(overlay)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, examining some event rate traces at random to get a sense for our data.  Feel free the run the next cell multiple times to get a sense for the diversity in firing rate among the cells that were imaged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(N,T) = event_rate.shape\n",
    "\n",
    "plt.figure(figsize=(10,2))\n",
    "t = np.arange(T)/imaging_Hz\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.plot(t,event_rate[np.random.choice(N)])\n",
    "plt.subplot(1,5,1)\n",
    "plt.xlabel('t (sec)')\n",
    "plt.ylabel('event rate (a.u.)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for some science. We'll first split up our continuous data into a series of sweeps, centered around the time of each stimulus onset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbefore = 2 # we will use a couple frames before each stim onset as a measure of \"baseline\"\n",
    "nafter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function to split the (N,T) continuous time series into traces\n",
    "# of duration Ttrial to yield an array of size (N,K,Ttrial)\n",
    "K = stim_frame.shape[0]\n",
    "stim_duration = np.diff(stim_frame,axis=1)\n",
    "mean_stim_duration = int(np.round(np.mean(stim_duration)))\n",
    "Ttrial = mean_stim_duration+nbefore+nafter\n",
    "trial_event_rate = np.zeros((N,K,Ttrial))\n",
    "for roi in range(N):\n",
    "    for trial in range(K):\n",
    "        trial_event_rate[roi,trial,:] = event_rate[roi,stim_frame[trial,0]-nbefore:\n",
    "                                                       stim_frame[trial,0]+mean_stim_duration+nafter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll plot what each neuron tends to do on average, across all different kinds of trials.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t = np.arange(-nbefore,mean_stim_duration+nafter)/imaging_Hz\n",
    "plt.plot(t,trial_event_rate.mean(1).T,alpha=0.1)\n",
    "plt.plot((0,0),(0,1),c='r')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Event Rate (a.u.)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do you notice anything about when the majority of neurons become most active relative to the stimulus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll further split up the data by stimulus condition.  This is so that we can look at the responses of neurons to different kinds of stimuli in order to infer their receptive fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the position (Px,Py) of the stimulus, split the array further into an array of size (N,NPx,NPy,Nreps,Ttrial)\n",
    "(NPy,NPx) = stim_location.max(0)+1\n",
    "Nreps = int(K/NPy/NPx)\n",
    "response = np.zeros((N,NPy,NPx,Nreps,Ttrial))\n",
    "for roi in range(N):\n",
    "    for Py in range(NPy):\n",
    "        for Px in range(NPx):\n",
    "            look_at = np.logical_and(Py==stim_location[:,0],Px==stim_location[:,1])\n",
    "            response[roi,Py,Px,:,:] = trial_event_rate[roi,look_at,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average over the 'Nreps' and 'Ttrial' column to yield retinotopic maps\n",
    "rf = response[:,:,:,:,nbefore:Ttrial-nafter].mean(-1).mean(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have averaged the responses across repetitions, we have an estimate of the receptive field for each neuron.  The following function will allow us to look at the receptive fields for all of our neurons at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function shows a series of arrays in rows of 15\n",
    "def imshow_in_rows(arr,rowlen=15,scale=0.5):\n",
    "    nrows = np.ceil(arr.shape[0]/rowlen)\n",
    "    plt.figure(figsize=(scale*rowlen,scale*nrows))\n",
    "    for k in range(arr.shape[0]):\n",
    "        plt.subplot(nrows,rowlen,k+1)\n",
    "        plt.imshow(arr[k])\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell make take several seconds to run, be patient\n",
    "imshow_in_rows(rf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This information on its own isn't that informative though.  You can see all of the receptive fields, but we cannot tell which cell each one belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following code to explore the receptive fields of the cells.  If you click on a cell in the left subplot, you should see it become highlighted, and then the right plot will show that cell's receptive field.  See if you think there is an underlying relationship between the spatial location of the cells and their receptive fields, and write down some of your observations below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,3))\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "mask_data = roi_mask.max(0)\n",
    "im = ax.imshow(mask_data, vmax=2)\n",
    "text = ax.text(0, 0, \"\", va=\"bottom\", ha=\"left\")\n",
    "\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "im2 = ax2.imshow(np.zeros_like(rf[0]), vmax=0.3)\n",
    "\n",
    "\n",
    "def onclick(event):\n",
    "    cell_n = np.where(roi_mask[:, int(event.ydata), int(event.xdata)])[0][0]\n",
    "    tx = 'cell number=%d' % (cell_n)\n",
    "    text.set_text(tx)\n",
    "    \n",
    "    mask_data = roi_mask.max(0)\n",
    "    mask_data[roi_mask[cell_n]==1] = 2\n",
    "    im.set_data(mask_data)\n",
    "    \n",
    "    im2.set_data(rf[cell_n])\n",
    "    im2.set_clim([0,rf[cell_n].max()])\n",
    "    fig.canvas.draw()\n",
    "       \n",
    "cid = fig.canvas.mpl_connect('button_press_event', onclick)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Share some of your findings here.  Do you notice anything surprising about the data?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our data, we have both stimulus-driven and stimulus-suppressed somatostatin neurons. We don't expect the center of mass metric to work well for the suppressive RF of the latter group, so we'll ignore them for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spont = trial_event_rate[:,:,:2].mean(-1).mean(-1)\n",
    "evoked = rf.mean(-1).mean(-1)\n",
    "_ = plt.scatter(spont,evoked,s=5)\n",
    "_ = plt.plot((0,0.4),(0,0.4),'r')\n",
    "_ = plt.xlabel('spontaneous event rate')\n",
    "_ = plt.ylabel('stimulus-evoked event rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We only want the cells that have a higher evoked event rate than spontaneous event rate.  Are those cells below or above the shown diagonal line in the figure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_at = evoked > spont  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question that we ultimately want to answer is:  Do the receptive field locations of these somatostatin neurons follow a topographic map? \n",
    "\n",
    "To investigate this quantitatively, we'll compute the ROI centers and receptive field centers using a simple metric, center of mass. Fortunately, Python has lots of libraries for things like this, so we don't have to write much ourselves here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_comy,rf_comx = zip(*[snm.center_of_mass(r) for r in rf])\n",
    "rf_comy = rf_comy*sq_deg\n",
    "rf_comx = rf_comx*sq_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_mask_comy,roi_mask_comx = zip(*[snm.center_of_mass(r) for r in roi_mask])\n",
    "roi_mask_comy = roi_mask_comy*pix_um\n",
    "roi_mask_comx = roi_mask_comx*pix_um"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to visually inspect our cells to see if they seem to follow a retinotopic map. We'll color the ROIs according to their azimuth in our first set of plots, and then their elevation in the next set.  Also, remember that we are looking at cells of varying depths, so we will show each of those in a different subplot to avoid problems with plotting overlapping cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "for k in range(4):\n",
    "    plt.subplot(1,4,k+1)\n",
    "    filt = np.logical_and(look_at,depth==k)\n",
    "    plt.imshow(np.nansum(roi_mask[filt]*rf_comx[filt][:,np.newaxis,np.newaxis],axis=0))\n",
    "    plt.title(\"Depth {}\".format(k+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "for k in range(4):\n",
    "    plt.subplot(1,4,k+1)\n",
    "    filt = np.logical_and(look_at,depth==k)\n",
    "    plt.imshow(np.nansum(roi_mask[filt]*rf_comy[filt][:,np.newaxis,np.newaxis],axis=0))\n",
    "    plt.title(\"Depth {}\".format(k+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From these plots, do you think that the receptive field centers are varying smoothly across the cells that we have imaged?  Why or why not?  If you see any outliers, describe them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can plot x-y location on the brain against x-y receptive field location to get a better idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "plt.subplot(2,2,1)\n",
    "plt.scatter(roi_mask_comx[look_at],rf_comx[look_at])\n",
    "plt.xlabel('rostral distance (um)')\n",
    "plt.ylabel('visual azimuth (deg)')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.scatter(roi_mask_comx[look_at],rf_comy[look_at])\n",
    "plt.xlabel('rostral distance (um)')\n",
    "plt.ylabel('visual elevation (deg)')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.scatter(roi_mask_comy[look_at],rf_comx[look_at])\n",
    "plt.xlabel('lateral distance (um)')\n",
    "plt.ylabel('visual azimuth (deg)')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.scatter(roi_mask_comy[look_at],rf_comy[look_at])\n",
    "plt.xlabel('lateral distance (um)')\n",
    "_ = plt.ylabel('visual elevation (deg)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do these plots match the intuition that you had for the previous question?  Explain what you think these plots are showing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at whether we can predict receptive field centers from location in the brain. We will use cross-validation, meaning that we will use part of our data to estimate the axes of the retinotopic map, and part of our data to test how accurately these retinotopic axes predict receptive field centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = sklearn.linear_model.LinearRegression()\n",
    "X = np.concatenate((roi_mask_comx[look_at,np.newaxis],roi_mask_comy[look_at,np.newaxis]),axis=1)\n",
    "y = np.concatenate((rf_comx[look_at,np.newaxis],rf_comy[look_at,np.newaxis]),axis=1)\n",
    "predicted = sklearn.model_selection.cross_val_predict(regr,X,y)\n",
    "score = sklearn.model_selection.cross_val_score(regr,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(y[:,0],predicted[:,0])\n",
    "plt.plot(y[:,0],y[:,0],c='r')\n",
    "plt.ylabel(\"RF center\")\n",
    "plt.xlabel(\"X-axis location in brain\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(y[:,1],predicted[:,1])\n",
    "plt.plot(y[:,1],y[:,1],c='r')\n",
    "plt.ylabel(\"RF center\")\n",
    "plt.xlabel(\"Y-axis location in brain\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the cross-validated R^2 values for each resampling\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How do you feel about these $R^2$ values that we got from this dataset?  If you are not familiar with $R^2$, take a quick look at [this wikipedia page](https://en.wikipedia.org/wiki/Coefficient_of_determination). Do you think that the location of cells does a good job of predicting the receptive field centers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
