{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image segmentation and calcium imaging ROI analysis lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Author:  Corey Webster, MCB PhD student in the Feller Lab at UC Berkeley`\n",
    "\n",
    "`The Watershed Image Segmentation part of this tutorial comes from Luis Pedro Coelho and can be found at his github repository `[HERE](https://github.com/luispedro/python-image-tutorial/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this tutorial is to familiarize you with some available tools in python for the purpose of automated ROI segmentation and analysis of calcium imaging traces. This tutorial should provide you with some foundation so that you can explore and develop image analysis tools in the future. \n",
    "\n",
    "In the first kernel of python code, we import the necessary libraries and tools. The first library that we import is [mahotas](http://mahotas.readthedocs.io/en/latest/edf.html), which has a lot of useful tools for image segmentation, particularly for images with biological information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mahotas as mh\n",
    "from matplotlib import pyplot as plt\n",
    "from ipywidgets import interact, fixed\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting some defaults for our plots\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) #10x8 inches\n",
    "plt.rcParams['image.cmap'] = 'gray' #set default colormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mahotas includes demo images, such as one of cells with a nuclear stain, feel free to uncomment the 'nuclear' demo image and play with segmentation using that (also uncomment the axis to make a single channel image from RGB). For this tutorial we'll be working with calcium imaging data from Muller Glia in the retina. The first image is an average intensity projection of the whole stack. Don't worry that it's glia, the algorithm should work with neurons also!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna = mh.imread('data/MullerGlia_sample2.tif')\n",
    "print(dna.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.imshow(dna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold\n",
    "The next step is to threshold our average intensity projection so that we can approximate regions of interest before putting it through further filters. You can play around with the threshold to see what works best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(thresh=(0.,4.0,0.05)) #between 1.0 and 16.0\n",
    "def check_thresh(thresh):\n",
    "    T_mean = thresh * dna.mean()  \n",
    "    _ = plt.imshow(dna > T_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scroll through the different thresholding values.  What differences do you notice when you change the value?  Explain the logic of how you selected a threshold value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian filter\n",
    "Mahotas has a [gaussian blur](https://en.wikipedia.org/wiki/Gaussian_blur) function that is similar to FIJIs gaussian filter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_val = ??? # put the value that you chose here\n",
    "\n",
    "dnaf = mh.gaussian_filter(dna, 2.)\n",
    "T_mean = thresh_val * dnaf.mean()\n",
    "bin_image = dnaf > T_mean\n",
    "_ = plt.imshow(bin_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll take the smoothened binary image and label it by assigning a different index to each region and then represent that index using the jet color map.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled, nr_objects = mh.label(bin_image)\n",
    "print(nr_objects)\n",
    "\n",
    "plt.imshow(labeled)\n",
    "plt.jet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating touching cells\n",
    "We now have the cells nicely separated from the background, but we have also merged several cells together.\n",
    "\n",
    "The general strategy we can use to separate the cells is the following:\n",
    "\n",
    "1. Smooth the image with a Gaussian filter (we need to specify the  $\\sigma$ parameter)\n",
    "2. Find regional maxima on this smoothed image to identify each cell\n",
    "3. Use [watershed](https://en.wikipedia.org/wiki/Watershed_(image_processing%29) on the [distance transformed](https://en.wikipedia.org/wiki/Distance_transform) image to separate cells.\n",
    "\n",
    "Play around with the interactive mode function to find the best value for $\\sigma$:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(sigma=(0.5,16.)) #between 1.0 and 16.0\n",
    "def check_sigma(sigma):\n",
    "    dnaf = mh.gaussian_filter(dna.astype(float), sigma)\n",
    "    maxima = mh.regmax(mh.stretch(dnaf))\n",
    "    maxima = mh.dilate(maxima, np.ones((5,5)))\n",
    "    plt.imshow(mh.as_rgb(np.maximum(255*maxima, dnaf), dnaf, dna > T_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explain the logic behind how you chose a value for sigma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input the sigma we just found into the gaussian filter to calculate the maxima for the watershed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = ??? # put the value that you chose here\n",
    "\n",
    "dnaf = mh.gaussian_filter(dna.astype(float), sigma)\n",
    "maxima = mh.regmax(mh.stretch(dnaf))\n",
    "maxima,_ = mh.label(maxima)\n",
    "_ = plt.imshow(maxima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Transform\n",
    "Calculate the distance transform to use for the watershed. Mahotas conveniently has a distance function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = mh.distance(bin_image)\n",
    "_ = plt.imshow(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Watershed\n",
    "\n",
    "Because of the way that the watershed function is defined in mahotas, we need to invert the distance transform. Also, for technical reasons, we convert to uint8.\n",
    "\n",
    "Finally, we can call mh.cwatershed with the dist image and the maxima as seeds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = 255 - mh.stretch(dist)\n",
    "watershed = mh.cwatershed(dist, maxima)\n",
    "_ = plt.imshow(watershed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the binary image as a mask to remove the background and we have our segmented cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed *= bin_image\n",
    "_ = plt.imshow(watershed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up regions\n",
    "\n",
    "We'll just run a few size filters and remove regions that touch the border since we might not get complete information from those ROIs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed = mh.labeled.remove_bordering(watershed)\n",
    "_ = plt.imshow(watershed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of the little stuff... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = mh.labeled.labeled_size(watershed)\n",
    "\n",
    "@interact(min_size = (0, 4000, 20))\n",
    "def do_plot(min_size):\n",
    "    filtered = mh.labeled.remove_regions_where(watershed, sizes < min_size)\n",
    "    print(\"filtering {}...\".format(min_size))\n",
    "    plt.imshow(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of the stuff that's too big to be a single cell. Sometimes cells too close together are difficult to threshold or filter out.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = mh.labeled.labeled_size(watershed)\n",
    "\n",
    "@interact(max_size = (0, 4000, 20))\n",
    "def do_plot(max_size):\n",
    "    filtered = mh.labeled.remove_regions_where(watershed, sizes > max_size)\n",
    "    print(\"filtering {}...\".format(max_size))\n",
    "    plt.imshow(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How did you pick your maximum and minimum size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we input our empirically derived size exclusion parameters. \n",
    "\n",
    "Relabeling is necessary because the .remove_regions_where() function just sets the removed regions to zero, but we want the labels to be consecutive. \n",
    "\n",
    "And Viola! Labeled segmented ROIs (without having to bribe an undergraduate to draw a bunch of little circles for you). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_size = ???  # Put your chosen value here\n",
    "max_size = ???  # Put your chosen value here\n",
    "\n",
    "filtered = (mh.labeled.remove_regions_where(watershed, sizes > max_size) &\n",
    "            mh.labeled.remove_regions_where(watershed, sizes < min_size))\n",
    "\n",
    "labeled, nr_objects = mh.labeled.relabel(filtered)\n",
    "print(\"Number of cells: {}\".format(nr_objects))\n",
    "\n",
    "_ = plt.imshow(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcium Imaging Analysis\n",
    "\n",
    "First step is to get the indices of each ROI so that we can use them to measure the average intensity of each ROI at each frame.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of all the pixel locations (indices) of each pixel in each ROI\n",
    "# Use this ROI location array to calculate the intensity of each pixel in each ROI\n",
    "# ROI_list contains a list of all the arrays of x or y values for each ROI,\n",
    "# such that ROI_list_xIndex[1] gives all the indices for the x values of ROI 1. \n",
    "\n",
    "ROI_list_xIndex = []\n",
    "ROI_list_yIndex = []\n",
    "\n",
    "for i in range(0, nr_objects):\n",
    "    rois = np.where(labeled == i)\n",
    "    rois = np.array(rois)\n",
    "    x_index = rois[1,:]\n",
    "    y_index = rois[0,:]\n",
    "   \n",
    "    ROI_list_xIndex.append(x_index)  #save an array of indices of each ROI to list ROI_array\n",
    "    ROI_list_yIndex.append(y_index)\n",
    "    \n",
    "print(len(ROI_list_xIndex))\n",
    "print(len(ROI_list_yIndex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the image series\n",
    "There are a number of ways in python to load an image series. If you want to display the full movie, try using [CalBlitz](https://github.com/agiovann/CalBlitz), although it isn't compatible with Jupyter notebooks. CalBlitz also has features like motion correction and is optimized for in vivo calcium imaging. PIL, skimage and mahotas can also be used to import *.tif files. For now we'll use skimage to import a tif series into an array; the kernel will return its dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.external.tifffile\n",
    "\n",
    "filepath = 'data/MullerGliaImageSeriesSample.tif'\n",
    "\n",
    "image_array = skimage.external.tifffile.imread(filepath, key = 0)\n",
    "print(image_array.shape) #array shape should be 90 frames that are 256x256 pixels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use our array of ROI indices and calculate the average intensity of each ROI over each frame and put that into a new array, avg_roi_array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have a list of arrays containing the indices of all the ROIs and a list of 256 x 256 \n",
    "# pixelarrays containing information from each frame. Here we use the ROI indices to calculate\n",
    "# average image intensity of each ROI at each frame, and then put that into an intensity array\n",
    "# that we'll use to calculate dF/Fo. \n",
    "\n",
    "# Pre-allocate the array where you will store the average image intensities\n",
    "avg_roi_array = np.zeros([len(ROI_list_yIndex), len(image_array)])\n",
    "\n",
    "for j in range(len(ROI_list_yIndex)): #loop over all ROIs\n",
    "    for i in range(len(image_array)): #loop over each time point\n",
    "        # Select the image for the time point\n",
    "        a = image_array[i]\n",
    "        # Take the average intensity for the pixels within the ROI\n",
    "        average_roi = np.average(a[ROI_list_yIndex[j], ROI_list_xIndex[j]])\n",
    "        # Save the average \n",
    "        avg_roi_array[j, i] = average_roi\n",
    "\n",
    "print(avg_roi_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(avg_roi_array[3])  #plot one example trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can put the ROI array into a pandas DataFrame and then use pandas to plot each ROI to visually inspect the data. If you want to see the data frame, just uncomment the dfT and comment out the plt.show().  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(avg_roi_array)\n",
    "dfT = df.T #Transpose the data frame so the columns are the ROIs. \n",
    "\n",
    "dfT #Print out entire dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = dfT.plot(subplots = True, figsize = (10, 10), legend = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate delta F/F  \n",
    "\n",
    "$$\\Delta F/F$$ \n",
    "\n",
    "As you can see from the axis, there are some real responses and some that are just noise around baseline. Usually you'll want to do some signal filtering and processing to identify the real calcium transient 'events' from the noise, but I'll let you figure out your favorite way to do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now calculate deltaF/F0 on the dataset. For F0 I'll use an average of the first 10 frames. \n",
    "roi = np.array(df)\n",
    "fo = np.zeros([len(df)], dtype = float)\n",
    "deltaF = np.zeros([len(df), len(roi[1,:])])\n",
    "for i in range(len(df)): \n",
    "    new_roi = roi[i]\n",
    "    fo[i] = np.average(roi[i,0:10]) #calculate F0 for each roi\n",
    "    deltaF[i] = ((roi[i] - fo[i])/fo[i]) #calculate deltaF/F0 for each ROI\n",
    "    \n",
    "\n",
    "deltaF_df = pd.DataFrame(deltaF)\n",
    "deltaF_df = deltaF_df.T\n",
    "\n",
    "ymin = -.05\n",
    "ymax = 1.8\n",
    "deltaF_df.plot(subplots = True, figsize = (10, 10), legend = True, ylim = (ymin, ymax))\n",
    "\n",
    "plt.ylim((ymin, ymax)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success!  You segmented an image and extracted fluorescence traces!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
